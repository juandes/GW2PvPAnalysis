---
title: "Guild Wars 2 PvP data analysis"
output: html_document
---

##Introduction

##Codebook and dataset

```{r, echo=FALSE}
require(ggplot2)
require(reshape2)
require(plyr)
require(dplyr)
require(randomForest)
require(e1071)
```

```{r, echo=FALSE}
setwd("~/Development/R/GW2PvPAnalysis")
df <- read.csv("~/Development/R/GW2PvPAnalysis/GW2_PvP_data.csv", stringsAsFactors=FALSE)
```

You can also embed plots, for example:

```{r, echo=FALSE}
#Remove unnecessary columns
df$X <- NULL
df$X.1 <- NULL
df$X.2 <- NULL

#Rename columns
colnames(df) <- c('map', 'red_score', 'blue_score', 'winner', 'red_1', 'red_2', 
                  'red_3', 'red_4', 'red_5', 'blue_1', 'blue_2', 'blue_3', 'blue_4',
                  'blue_5')

#If the red team won, the value is 0, otherwise 1
df$winner[df$red_score > df$blue_score] <- 0
df$winner[df$red_score < df$blue_score] <- 1

#Change the names of the classes for numbers
df[5:14][df[5:14] == 'ele'] <- 1
df[5:14][df[5:14] == 'engi'] <- 2
df[5:14][df[5:14] == 'g'] <- 3
df[5:14][df[5:14] == 'mes'] <- 4
df[5:14][df[5:14] == 'necro'] <- 5
df[5:14][df[5:14] == 'ran'] <- 6
df[5:14][df[5:14] == 't'] <- 7
df[5:14][df[5:14] == 'war'] <- 8
```

##The maps
```{r,echo=FALSE}
table(df$map)

qplot(map, data=df, geom="histogram", main = "Histogram of map usage", xlab = "Map",
      ylab="Count", fill=I("blue")) +
  scale_x_discrete(breaks = 1:4, labels = c("1" = "Kyhlo","2" = "Niflhel", "3" = "Foefire",
                                            "4" = "Silent Storm"))
```

Percentage of maps
```{r,echo=FALSE}
prop.table(table(df$map))
```

The previous table shows the percentage of map selection for all the four maps 
available on ranked PvP. The first column is for the Battle of Kyhlo map (12.60%),
followed by Forest of Niflhel (44.54%), Legacy of the Foefire (27.73%) and the 
last column is for Temple of the Silent Storm (15.12%).

##Score and result of the matches

This part of the analysis is related to the scores the matches and the results.
First, we will give an overview of the final scores and the outcome of the matches,
followed by an in depth view at the scores of the victor teams and the defeated
teams.

###Overall view of the score and result

We will start this section by displaying a table with the frequency of wins for
both teams.

```{r,echo=FALSE}
winnerdf <- as.data.frame(table(df$winner))
colnames(winnerdf) <- c("Team", "Frequency")
winnerdf[,1] <- c("Red team", "Blue team")
winnerdf
```

The red team won 49 of the matches or `r round(49/(49 + 70)*100, 2)`% while the 
blue team won 70 or `r round(70/(49+70)*100, 2)`% of the matches. The percentages 
of victories per map follows this same pattern. In the map Battle of Kyhlo, the 
red team won `r round(7/(7+8)*100, 2)`% of the matches and the blue team won 
`r round(8/(7+8)*100, 2)`%, making this the only map where the blue team obtained
more victories than the red team. For the next map, Forest of Niflhel, the 
respective percentages were `r round(21/(21+32)*100, 2)`% and 
`r round(32/(21+32)*100, 2)`%, for Legacy of the Foefire `r round(11/(11+22)*100, 2)`% 
and for Temple of the Silent Storm, `r round(10/(10+8)*100, 2)`% and
`r round(8/(10+8)*100, 2)`%. This is shown in the next table.

```{r, echo=FALSE}
wins.per.map <- table(df$map, df$winner)
wins.per.map <- data.frame(map = c('Battle of Kyhlo','Forest of Niflhel',
                                   'Legacy of the Foefire','Temple of the Silent Storm'),
                           red_team = wins.per.map[,1], blue_team = wins.per.map[,2],
                           stringsAsFactors=FALSE)
                                
wins.per.map.percentage <- wins.per.map
wins.per.map.percentage$red.team.win.percent <- wins.per.map$red_team/(wins.per.map$red_team +
                                                                       wins.per.map$blue_team)*100
wins.per.map.percentage$blue.team.win.percent <- wins.per.map$blue_team/(wins.per.map$red_team +
                                                                         wins.per.map$blue_team)*100
wins.per.map.percentage
```

Next, we will discuss the gap between the final scores of the matches.

```{r, echo=FALSE}
df$score.difference <- abs(df$red_score - df$blue_score)
score.difference.summary <- summary(df$score.difference)
score.difference.summary
```

As seen on the previous table, the was a match where one of the teams lost by 9
points while on the other hand, there was another match where the defeated team,
lost by 528 points. The next histogram shows the distribution of the score
differences. Afterwards, we will display the same kind of histograms for the score
difference by map.

```{r, echo=FALSE}
hist(df$score.difference, prob = TRUE)
rug(df$score.difference)
lines(density(df$score.difference), col="blue", lwd=2)
lines(density(df$score.difference, adjust=2), lty="dotted", col="darkgreen", lwd=2)
```

Battle of Kyhlo

```{r, echo=FALSE}
hist(filter(df, map == 1)$score.difference, prob = TRUE)
rug(filter(df, map == 1)$score.difference)
lines(density(df$score.difference), col="blue", lwd=2)
lines(density(df$score.difference, adjust=2), lty="dotted", col="darkgreen", lwd=2)
```

Forest of Niflhel

```{r, echo=FALSE}
hist(filter(df, map == 2)$score.difference, prob = TRUE)
rug(filter(df, map == 2)$score.difference)
lines(density(df$score.difference), col="blue", lwd=2)
lines(density(df$score.difference, adjust=2), lty="dotted", col="darkgreen", lwd=2)
```

Legacy of the Foefire

```{r, echo=FALSE}
hist(filter(df, map == 3)$score.difference, prob = TRUE)
rug(filter(df, map == 3)$score.difference)
lines(density(df$score.difference), col="blue", lwd=2)
lines(density(df$score.difference, adjust=2), lty="dotted", col="darkgreen", lwd=2)
```

Temple of the Silent Storm

```{r, echo=FALSE}
hist(filter(df, map == 4)$score.difference, prob = TRUE)
rug(filter(df, map == 4)$score.difference)
lines(density(df$score.difference), col="blue", lwd=2)
lines(density(df$score.difference, adjust=2), lty="dotted", col="darkgreen", lwd=2)
```



Now we will present four visualizations. The first one presents the frequency of
victories of both teams across all the maps, the following two present the scores
of both teams and the last one is a scatterplot the final score of each match of
both teams.


```{r,echo=FALSE}
winners_and_score <- melt(wins.per.map, id='map')
colnames(winners_and_score) <- c('Map', 'Team', 'Frequency')
ggplot(data=winners_and_score, aes(x=Team, y=Frequency, fill=Team))+
  geom_bar(stat='identity') +
  facet_wrap(~Map) +
  ggtitle("Scores of both teams per map")
```

```{r, echo=FALSE}
scoresdf <- data.frame(match_number = seq(1,119), red_score = df$red_score, blue_score = df$blue_score, map = df$map)
qplot(match_number, red_score, data = scoresdf, size = red_score, alpha = red_score, colour = "red") + theme(legend.position = "none")
qplot(match_number, blue_score, data = scoresdf, size = blue_score, alpha = blue_score, colour = blue_score) + theme(legend.position = "none")
```

```{r, echo=FALSE}
qplot(x = df$red_score, y = df$blue_score, geom = "point", alpha = I(0.5), size = I(5))
```

The previous scatterplot shows the relation between the final scores of both teams.
Those points on the upper left corner and bottom right are matches where one of
the teams won by a great difference. If we perform a correlation test on these values,
we obtained a correlation of `r cor(df$red_score, df$blue_score)`, which means
that there is some kind of (negative) correlation on the data. To further confirm
this, we calculated the p-value (found after this) which by being so small implies
there is a strong evidence against the null hypothesis, which is that the correlation
is 0 (no relation between both scores).

This table presents correlation, p-value and other statistics.
```{r, echo=FALSE}
cor.test(df$red_score, df$blue_score)
```

The next topic to discuss are the scores of the matches. Here, we will take a look at how distributed these scores are and we will show some statistics about them accompanied by several plots. 

###Final scores of the winning team
In this section we will take a look at a summary of the final scores of the winners of all the 
119 matches recorded in this dataset. Before continuining, we would like to mention
that a PvP match in Guild Wars 2 ends when one of the both teams reach a score 
greater or equal to 500.

```{r, echo=FALSE}
winner.score <- pmax(df$red_score, df$blue_score)
summary(winner.score)
```

As expected, the final scores does not vary that much (most of them are close to 500) 
with some them, way over 500 as is the case of the max value of 624; the standard 
deviation of the scores is `r sd(winner.score)`. The reason regarding the score 
of 624 is because one of the maps (Legacy of the Foefire), has an objective that 
gives 150 points to a team.

###Losers score

Unlike the winner's score, the final score of the loser team could be anything from 0 (if you are really bad) up to 499 (in most cases).

The following list shows the scores of the loser's team.

```{r}
loser_score <- pmin(df$red_score, df$blue_score)
loser_score
```

The scores are more varied that the winner scores.

The next table shows a summary of this scores, followed by the standard deviation.

```{r}
summary(loser_score)
print(sd(loser_score))
```

The summary table shows that during one game, the team who lost, just obtained 10 points (ouch!), making this the minimum value across the whole dataset, while the average was 328.2 and the max was 491 (so close to winning). We also calculated the standard deviation, which is `r print(sd(loser_score))`, a value greater than the standard deviation of the winner's score, which was `r print(sd(winner.score))`. The following two figures shows these results via a histogram (that includes a density line) and a boxplot.

```{r}
hist(loser_score, prob=TRUE, col="grey")# prob=TRUE for probabilities not counts
rug(loser_score)
lines(density(loser_score), col="blue", lwd=2) # add a density estimate with defaults
lines(density(loser_score, adjust=2), lty="dotted", col="darkgreen", lwd=2) #smoother
#Hacer esto mismo por map
```

The histogram shows that the score of the defeated team during most matches was in the range of 350 to 400 and that there were a few games where the score of the defeated team was less than 100.

```{r, echo=FALSE}
boxplot(loser_score, main = "Scores of the defeated team", ylab = "Score")
boxplot.stats(loser_score)$out
```

The previous figure, a boxplot, shows the distribution of the scores. The box goes from the first quartile (Q1), which is `r boxplot.stats(loser_score)$stats[2]`  to the third quartile (Q3), `r boxplot.stats(loser_score)$stats[4]`. The line in the middle shows the median, which is `r boxplot.stats(loser_score)$stats[3]` and the top and lower whiskers shows the maximum value (excluding the outliers), which is `r boxplot.stats(loser_score)$stats[5]` and the minimum value (also excluding the outliers), which for this dataset is `r boxplot.stats(loser_score)$stats[1]`. The two dots at the bottom of the plot are the outliers. The values of these two values are 10 and 13.

The next table shows a summary of the boxplot.

```{r, echo=FALSE}
boxplot.stats(loser_score)$stats
```

The values represent the minimum, first quartile, median, third quartile and 
maximum.

## Composition of the teams

The last part of this analysis is about the composition of the teams. Here, we
will study the structure of the teams while answering several questions on the way.
This section will follow a similar structure to the previous ones. We will start 
with a summary and then a detailed analysis about certain topics. Besides this, 
this section introduces several machine learning algorithms that will be used to 
try to predict the outcome of the matches based on the composition of the team 
and the map where the match was played.

As mentioned before, our dataset is made of 119 matches. For this reason, we
actually have 238 observations of team composition (because there are two teams
per match).

### Summary of team composition

This section will start with a summary of the structure of the teams. We will
present the composition of the teams in terms of professions or classes. In
addition to this, we will be showing the amount of teams that were incomplete.

The first question we will answer is: What is the frequency and percentage of 
professions across the dataset?

```{r, echo=FALSE}
team.composition <- data.frame(class.1 = numeric(0), class.2 = numeric(0), 
                               class.3 = numeric(0), class.4 = numeric(0), 
                               class.5 = numeric(0))
red.team.composition <- df[5:9]
blue.team.composition <- df[10:14]
colnames(red.team.composition) <- c("class.1", "class.2", "class.3", "class.4", 
                                    "class.5")
colnames(blue.team.composition) <- c("class.1", "class.2", "class.3", "class.4",
                                     "class.5")
team.composition <- rbind(team.composition, red.team.composition, blue.team.composition)
```


#### What is the frequency and percentage of professions across the dataset?

```{r, echo=FALSE}
frequency.percentage.classes <- sapply(1:8, function(class.number) 
  sum(sapply(team.composition, function(x) sum(x == class.number))))
frequency.percentage.classes <- as.data.frame(frequency.percentage.classes)
rownames(frequency.percentage.classes) <- c("Elementalist", "Engineer", "Guardian", "Mesmer",
                                 "Necromancer", "Ranger", "Thief", "Warrior")
colnames(frequency.percentage.classes) <- c("Frequency")
frequency.percentage.classes$Percentage <- round(frequency.percentage.classes$Frequency/(sum(frequency.percentage.classes$Frequency) + 17) * 100, 2) # 17 missing players.
frequency.percentage.classes
```

We can see that the most common class across the matches was the Ranger, with a
frequency of 299 (25.12%), however, the reason why this number much larger than
the other frequencies is the fact that all the matches we did was using a Ranger,
so every single match had at least one Ranger. On the other end, there is the
Engineer, with a frequency of 70 (5.88%).

If the percentages are summed, the result is 
`r round(sum(frequency.percentage.classes$Percentage), 2)`, instead of 100%. This
bring us to other next question: What is the amount of missing players?

#### What is the amount of missing players?

```{r, echo=FALSE}
frequency.percentage.missing.players <- sum(sapply(team.composition, function(x) sum(x == 0)))
frequency.percentage.missing.players <- as.data.frame(frequency.percentage.missing.players)
rownames(frequency.percentage.missing.players) <- c("Missing players")
colnames(frequency.percentage.missing.players) <- c("Frequency")
frequency.percentage.missing.players$Percentage <- round(frequency.percentage.missing.players$Frequency/(sum(frequency.percentage.classes$Frequency) + 17) * 100, 2) # 17 missing players.
frequency.percentage.missing.players
```

17 players were missing. We do not know if these players were missing since the
beginning of the game (for some reason sometimes teams can contain less than 5 players),
or if they disconnected. 

#### Is there a repeated team composition?

In this question we looked for those team compositions that appears more than once.

```{r, echo=FALSE}
frequent.teams <- ddply(team.composition,names(team.composition),summarize, 
                        Frequency = length(class.1))
frequent.teams <- frequent.teams[frequent.teams$Frequency > 1,]
frequent.teams[1:5][frequent.teams[1:5] == 5] <- "Necromancer"
frequent.teams[1:5][frequent.teams[1:5] == 8] <- "Warrior"
frequent.teams[1:5][frequent.teams[1:5] == 6] <- "Ranger"
frequent.teams[1:5][frequent.teams[1:5] == 1] <- "Elementalist"
frequent.teams[1:5][frequent.teams[1:5] == 7] <- "Thief"
frequent.teams[1:5][frequent.teams[1:5] == 3] <- "Guardian"
frequent.teams
```

As the table shows, there were three team configurations that were repeated more
than once.

#### What is the outcome of the match when a team is made of 3 or more of the same profession?

```{r, echo=FALSE}
# Find matches that had at least 3 of the same professions
three.or.more <- team.composition[apply(team.composition, 1, function(X) any(table(X) >= 3)),]



scores.for.red <- df$winner # 1 means red lose, 0 means red won (0 means victory, 1 defeat)
scores.for.blue <- sapply(df$winner, function(x) if (x == 1) { 0 } else { 1 })
scores.for.red <- as.data.frame(scores.for.red)
scores.for.blue <- as.data.frame(scores.for.blue)
colnames(scores.for.red) <- c("Result")
colnames(scores.for.blue) <- c("Result")
team.composition.result <- data.frame(result = numeric(0))
team.composition.result <- rbind(team.composition.result, scores.for.red, scores.for.blue)
# Get the result of the matches. We are using df[4] twice because of the structure
# of team.composition dataframe
#team.composition.result <- data.frame(result = numeric(0))
#team.composition.result <- rbind(team.composition.result, df[4], df[4])

# Get the result of the particular matches using the indexes of three.or.more
three.or.more <- cbind(three.or.more, 
                       result = team.composition.result[as.numeric(rownames(three.or.more)),])
#three.or.more.result <- team.composition.result[as.numeric(rownames(three.or.more)),]
#three.or.more.teams <- c(rep.int(0, 119), rep.int(1, 119))
#three.or.more.teams <- data.frame(team = numeric(nrow(team.composition)))
#three.or.more.teams$team[120: nrow(three.or.more.teams)] <- 1
#three.or.more.teams$team <- rbind(three.or.more.teams, rep(1,100))
#three.or.more.teams <- c(rep.int(0, 119), rep.int(1, 119))
#three.or.more <- cbind(three.or.more, 
                       #team = three.or.more.teams[as.numeric(rownames(three.or.more)),])

```

In the dataset there are `r nrow(three.or.more)` teams that has at least 3
characters playing the same class. Of those `r nrow(three.or.more)` teams,
`r nrow(three.or.more[three.or.more$result == 0,])` won the matches.

These are the composition of those teams.

```{r, echo=FALSE}
three.or.more.victory <- three.or.more[three.or.more$result == 0,]
three.or.more.victory[three.or.more.victory == 1] <- "Elementalist"
three.or.more.victory[three.or.more.victory == 2] <- "Engineer"
three.or.more.victory[three.or.more.victory == 3] <- "Guardian"
three.or.more.victory[three.or.more.victory == 4] <- "Mesmer"
three.or.more.victory[three.or.more.victory == 5] <- "Necromancer"
three.or.more.victory[three.or.more.victory == 6] <- "Ranger"
three.or.more.victory[three.or.more.victory == 7] <- "Thief"
three.or.more.victory[three.or.more.victory == 8] <- "Warrior"
three.or.more.victory
```


#### Is it possible to predict the outcome of a match based on the structure of the team?

```{r, echo=FALSE}
team.result <- cbind(team.composition, team.composition.result)
colnames(team.result)[6] <- "result"
team.result$result[team.result$result == 0 ] <- "won"
team.result$result[team.result$result == 1 ] <- "lost"
team.result$result <- as.factor(team.result$result)
```
The last section of this analysis, introduces two classification models, naive
Bayes classifier and random forest, that will learn from our data with the purpose
of classifying the outcome of a match based on the composition of the team. The
two possible outcome are victory or defeat.

The basic idea behind these classifiers could be divided in two parts. During
the first part, often called the training part, the model is feeded with data that
already have the outcome of the match. In other words, we are teaching the model.
The table below, shows an example of this. It has the structure of the team
(3 rangers, presented with the number 6 and two quitters, presented as 0), and
the result, which is 'lost'.

```{r, echo=FALSE}
team.result[1,]
```

During the second part, after the training is completed, we will send differerent
team compositions to the model and it will output the outcome of the match based
on what it already learned.

The dataset will be split 70% for training and 30% for testing.

##### Random Forest

The following table is a direct output that has information about the model and
the results.

```{r, echo=FALSE}
index <- sample(2, nrow(team.result), replace=TRUE, prob=c(0.8, 0.2))
train.data <- team.result[index == 1, ]
test.data <- team.result[index == 2, ]

# Create the random forest model and train it.
rf <- randomForest(result ~ ., data = train.data, ntree = 70, proximity = TRUE)
confusion.matrix.rf <- table(predict(rf), train.data$result)
classification.error <- round((confusion.matrix.rf[2, 1] + confusion.matrix.rf[1, 2]) /
                           sum(confusion.matrix.rf) * 100, 2)
rf

# Prediction using the test data
pred <- predict(rf, test.data)
pred.confusion.matrix <- table(pred, test.data$result)
test.classification.error <- round((pred.confusion.matrix[2, 1] + pred.confusion.matrix[1, 2]) /
                                     sum(pred.confusion.matrix) * 100, 2)
```

The model report an error rate of `r classification.error`%, in other words
`r classification.error`% of the classifications performed during training,
were incorrect. More details about this can be found at the confusion matrix at
the bottom of the table.

The testing dataset had a classification error of `r test.classification.error`%.
This is the confusion matrix:

```{r, echo=FALSE}                           
pred.confusion.matrix
```

##### Naive Bayes classifier

```{r, echo=FALSE}
#Create and train the model
bayes.classifier <- naiveBayes(result ~ ., data = train.data)
train.data <- as.data.frame(cbind(class.1 = as.numeric(train.data$class.1), 
                                  class.2 = as.numeric(train.data$class.2),
                                  class.3 = as.numeric(train.data$class.3), 
                                  class.4 = as.numeric(train.data$class.4),
                                  class.5 = as.numeric(train.data$class.5), 
                                  result = as.numeric(train.data$result)))
pred <- predict(bayes.classifier, train.data)
table(pred, train.data$result)
bayes.classifier

#Test the model

test.data <- as.data.frame(cbind(class.1 = as.numeric(test.data$class.1), 
                                 class.2 = as.numeric(test.data$class.2),
                                 class.3 = as.numeric(test.data$class.3), 
                                 class.4 = as.numeric(test.data$class.4),
                                 class.5 = as.numeric(test.data$class.5), 
                                 result = as.numeric(test.data$result)))
bayes.prediction <- predict(bayes.classifier, test.data)
bayes.pred.confusion.matrix <- table(bayes.prediction, test.data$result)

bayes.pred.confusion.matrix
```



